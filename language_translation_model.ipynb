{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tikendraw/language-translation-model/blob/main/language_translation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1hJ48ytxM3b"
      },
      "source": [
        "# Language Translation Model (English to Hindi)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrmDJdXC9SfD",
        "outputId": "d3f8372b-8c31-450b-fede-e2420a32c687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'language-translation-model'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 22 (delta 7), reused 11 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), 376.54 KiB | 3.73 MiB/s, done.\n",
            "/content/language-translation-model\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    \n",
        "    ! git clone https://github.com/tikendraw/language-translation-model.git \n",
        "    os.chdir('language-translation-model') \n",
        "    print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cxy3JvX9Fw4",
        "outputId": "5d215f68-c3b5-428a-f5eb-0492de345962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTf version:  2.11.0\n",
            "GPU:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "! pip install polars -q\n",
        "import polars as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model , optimizers\n",
        "from tensorflow.keras.layers import Attention,GRU, LSTM, Bidirectional, Dense, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, AveragePooling1D, Dropout, concatenate, Concatenate\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install tensorflow_hub -q\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print('Tf version: ',tf.__version__)\n",
        "print('GPU: ', is_gpu:=len(tf.config.list_physical_devices('GPU')))\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "os.environ[\"TFHUB_CACHE_DIR\"] = './tmp/tfhub'\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
        "None\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "if is_gpu:\n",
        "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "    config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(physical_devices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nY49Vs8mxGcD"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'http://www.manythings.org/anki/hin-eng.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H7P06oG8xiS7"
      },
      "outputs": [],
      "source": [
        "# # # Download the dataset\n",
        "# if 'google.colab' in sys.modules:\n",
        "#     # donwload\n",
        "#     !wget $dataset_url -P dataset\n",
        "\n",
        "#     # # Unzip the downloaded file\n",
        "#     !unzip ./dataset/hin-eng.zip -d ./dataset\n",
        "\n",
        "#     # # Show size\n",
        "#     !du -h  ./dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITptJktjzLho"
      },
      "source": [
        "# Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4XP6M5Eb0t5F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vraPNhwl0t2Z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./dataset/hin.txt', sep = '\\t', new_columns = ['english', 'hindi', 'somethingelse'])[['english','hindi']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsHrOgJX0t0m",
        "outputId": "b4f0a62c-5bb2-44d7-8c7e-976221a127ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2908, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "_iYNVAyD0tyx",
        "outputId": "3218273c-7489-4442-df60-5af347525b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 2)\n",
              "┌─────────────────────────────────────┬────────────────────────────────────┐\n",
              "│ english                             ┆ hindi                              │\n",
              "│ ---                                 ┆ ---                                │\n",
              "│ str                                 ┆ str                                │\n",
              "╞═════════════════════════════════════╪════════════════════════════════════╡\n",
              "│ Duck!                               ┆ झुको!                               │\n",
              "│ Mother and I are different in ev... ┆ मम्मी और मैं किसी भी पहलू में एक...      │\n",
              "│ Do you jog every day?               ┆ क्या आप हर दिन जॉगिंग करते हैं?         │\n",
              "│ I have a headache.                  ┆ मुझे सिरदर्द हो रहा है।                │\n",
              "│ ...                                 ┆ ...                                │\n",
              "│ She wanted to have her hair cut,... ┆ वह अपने बाल कटवाना चाहती थी, पर ... │\n",
              "│ He's sleeping like a baby.          ┆ वह बच्चे की तरह सो रहा है।            │\n",
              "│ He came running.                    ┆ वह भागते हुए आया।                    │\n",
              "│ In case I can't come, I'll give ... ┆ अगर मैं नहीं आ पाया तो तुम्हें प...       │\n",
              "└─────────────────────────────────────┴────────────────────────────────────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style>\n",
              ".pl-dataframe > thead > tr > th {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "\n",
              "<table border=\"1\" class=\"dataframe pl-dataframe\">\n",
              "<small>shape: (10, 2)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "english\n",
              "</th>\n",
              "<th>\n",
              "hindi\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;Duck!&quot;\n",
              "</td>\n",
              "<td>\n",
              "&quot;झुको!&quot;\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;Mother and I a...\n",
              "</td>\n",
              "<td>\n",
              "&quot;मम्मी और मैं क...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;Do you jog eve...\n",
              "</td>\n",
              "<td>\n",
              "&quot;क्या आप हर दिन...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;I have a heada...\n",
              "</td>\n",
              "<td>\n",
              "&quot;मुझे सिरदर्द ह...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;Classical musi...\n",
              "</td>\n",
              "<td>\n",
              "&quot;मुझे शास्त्रीय...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;Tom may invite...\n",
              "</td>\n",
              "<td>\n",
              "&quot;टॉम हमें आमंत्...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;She wanted to ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;वह अपने बाल कट...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;He&#x27;s sleeping ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;वह बच्चे की तर...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;He came runnin...\n",
              "</td>\n",
              "<td>\n",
              "&quot;वह भागते हुए आ...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;In case I can&#x27;...\n",
              "</td>\n",
              "<td>\n",
              "&quot;अगर मैं नहीं आ...\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "swlPFpr-0txP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BDxEUwx2jFxB"
      },
      "outputs": [],
      "source": [
        "UNITS = 32\n",
        "EMBEDDING_DIMS = 16\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceSkRUmM0twM"
      },
      "source": [
        "# Prepare the data `tf.data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BCw6ZgqV0tuW"
      },
      "outputs": [],
      "source": [
        "# Split the data for train and val\n",
        "train_df, val_df = train_test_split(df, test_size = .02, random_state = 4 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA0bZi7Z0ttP",
        "outputId": "5a98ec10-48da-4b96-bca4-a227e5028233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape:  (2849, 2)\n",
            "val shape:  (59, 2)\n"
          ]
        }
      ],
      "source": [
        "print('train shape: ', train_df.shape)\n",
        "print('val shape: ', val_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z5rNSvh2jFxE"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "puSucMUn0tq-"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df['english'].to_list(), train_df['hindi'].to_list())).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_df['english'].to_list(), val_df['hindi'].to_list())).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqH0xQMUjFxG",
        "outputId": "f0a7e942-de84-4714-ce0c-327105182838"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_APB0Ah64b26"
      },
      "outputs": [],
      "source": [
        "\n",
        "# preprocessing text\n",
        "def tf_lower_and_split_punct_en(text):\n",
        "    # Split accented characters.\n",
        "    # text = tf.text.normalize_utf8(text, 'NFKD')\n",
        "    text = tf.strings.lower(text)\n",
        "    # Keep space, a to z, and select punctuation.\n",
        "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "    # Add spaces around punctuation.\n",
        "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
        "    # Strip whitespace.\n",
        "    text = tf.strings.strip(text)\n",
        "\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# preprocessing text\n",
        "def tf_lower_and_split_punct_hi(text):\n",
        "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfNyTkJ56pPt",
        "outputId": "0c0ba783-a39d-41fa-ba34-3e0f1f28fe88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "उन्होंने मेरी का| मज़ाक उड़ाया\n",
            "tf.Tensor(b'[START] \\xe0\\xa4\\x89\\xe0\\xa4\\xa8\\xe0\\xa5\\x8d\\xe0\\xa4\\xb9\\xe0\\xa5\\x8b\\xe0\\xa4\\x82\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa4\\xbe |  \\xe0\\xa4\\xae\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc\\xe0\\xa4\\xbe\\xe0\\xa4\\x95 \\xe0\\xa4\\x89\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc\\xe0\\xa4\\xbe\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe [END]', shape=(), dtype=string)\n",
            "[START] उन्होंने मेरी का |  मज़ाक उड़ाया [END]\n"
          ]
        }
      ],
      "source": [
        "some_hindi_text = 'उन्होंने मेरी का| मज़ाक उड़ाया'\n",
        "print(some_hindi_text)\n",
        "b= tf_lower_and_split_punct_hi(some_hindi_text)\n",
        "print(b)\n",
        "print(b.numpy().decode())\n",
        "del(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRZEds9s0tpU",
        "outputId": "e80f9327-784b-4ab7-c66e-290fc0b9f6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:  tf.Tensor(\n",
            "[b'Smoking will do you a lot of harm.'\n",
            " b'He will write for hours at a time.' b'Tom is my idol.' b'Go away!'\n",
            " b'I was born in 1960.' b'What do you like to do?'\n",
            " b'Father objected to my going to the mountain alone.'\n",
            " b\"It's already nine o'clock.\" b\"Nobody's around.\" b'We went shopping.'\n",
            " b'His new book is going to come out next month.'\n",
            " b'He seemed surprised by my ignorance.'\n",
            " b\"I don't think that anyone noticed what we did.\" b'He likes oranges.'\n",
            " b'It is already eleven.' b'Is your father a teacher?'\n",
            " b'She cut the cake into six pieces and gave one to each of the children.'\n",
            " b'Have you ever failed an exam?'\n",
            " b'He left his parents when he was eight years old.'\n",
            " b'She plays tennis very well.' b'I am reading a book.'\n",
            " b'I was caught in a shower and was drenched to the skin.'\n",
            " b'This machine is superior in quality to that one.'\n",
            " b'Half of the apples are rotten.'\n",
            " b\"I'm going to go buy some materials today.\" b'The house was in flames.'\n",
            " b'He wanted to buy the book.' b\"I'd like a Bloody Mary.\"\n",
            " b'I wish I had more time to talk with you.' b'My father is very nice.'\n",
            " b'The thieves pulled open all the drawers of the desk in search of money.'\n",
            " b'Remove your shirt and lie down.'], shape=(32,), dtype=string)\n",
            "j:  tf.Tensor(\n",
            "[b'\\xe0\\xa4\\xa7\\xe0\\xa5\\x82\\xe0\\xa4\\xae\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa4\\xaa\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8 \\xe0\\xa4\\x86\\xe0\\xa4\\xaa\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xb9\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8\\xe0\\xa4\\xbf \\xe0\\xa4\\xaa\\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\x81\\xe0\\xa4\\x9a\\xe0\\xa4\\xbe\\xe0\\xa4\\x8f\\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x98\\xe0\\xa4\\x82\\xe0\\xa4\\x9f\\xe0\\xa5\\x8b \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\x8f \\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\x96 \\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x9f\\xe0\\xa5\\x89\\xe0\\xa4\\xae \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe \\xe0\\xa4\\x86\\xe0\\xa4\\xa6\\xe0\\xa4\\xb0\\xe0\\xa5\\x8d\\xe0\\xa4\\xb6 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x9a\\xe0\\xa4\\xb2\\xe0\\xa5\\x87 \\xe0\\xa4\\x9c\\xe0\\xa4\\xbe\\xe0\\xa4\\x93!'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa5\\xa7\\xe0\\xa5\\xaf\\xe0\\xa5\\xac\\xe0\\xa5\\xa6 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xaa\\xe0\\xa5\\x88\\xe0\\xa4\\xa6\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\x86 \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xa4\\xe0\\xa4\\xae\\xe0\\xa5\\x8d\\xe0\\xa4\\xb9\\xe0\\xa5\\x87 \\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe \\xe0\\xa4\\x85\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9b\\xe0\\xa4\\xbe \\xe0\\xa4\\xb2\\xe0\\xa4\\x97\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x88?'\n",
            " b'\\xe0\\xa4\\xaa\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\x9c\\xe0\\xa5\\x80 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa4\\xb9\\xe0\\xa4\\xbe\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc \\xe0\\xa4\\xaa\\xe0\\xa4\\xb0 \\xe0\\xa4\\x85\\xe0\\xa4\\x95\\xe0\\xa5\\x87\\xe0\\xa4\\xb2\\xe0\\xa5\\x87 \\xe0\\xa4\\x9c\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc\\xe0\\xa5\\x80 \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xa5\\xe0\\xa5\\x87\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xa8\\xe0\\xa5\\x8c \\xe0\\xa4\\xac\\xe0\\xa4\\x9c \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x95\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x86\\xe0\\xa4\\xb8\\xe0\\xa4\\xaa\\xe0\\xa4\\xbe\\xe0\\xa4\\xb8 \\xe0\\xa4\\x95\\xe0\\xa5\\x8b\\xe0\\xa4\\x88 \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb9\\xe0\\xa4\\xae \\xe0\\xa4\\x96\\xe0\\xa4\\xb0\\xe0\\xa5\\x80\\xe0\\xa4\\xa6\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x97\\xe0\\xa4\\x8f \\xe0\\xa4\\xa5\\xe0\\xa5\\x87\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa5\\x80 \\xe0\\xa4\\xa8\\xe0\\xa4\\x88 \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\xac \\xe0\\xa4\\x85\\xe0\\xa4\\x97\\xe0\\xa4\\xb2\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x9b\\xe0\\xa4\\xaa\\xe0\\xa5\\x87\\xe0\\xa4\\x97\\xe0\\xa5\\x80\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\x85\\xe0\\xa4\\x9c\\xe0\\xa5\\x8d\\xe0\\xa4\\x9e\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8 \\xe0\\xa4\\xaa\\xe0\\xa4\\xb0 \\xe0\\xa4\\x86\\xe0\\xa4\\xb6\\xe0\\xa4\\x82\\xe0\\xa4\\x95\\xe0\\xa4\\xbe \\xe0\\xa4\\x9c\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x81\\xe0\\xa4\\x9d\\xe0\\xa5\\x87 \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xb2\\xe0\\xa4\\x97\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa4\\xbf \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xb8\\xe0\\xa5\\x80 \\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xad\\xe0\\xa5\\x80 \\xe0\\xa4\\xa6\\xe0\\xa5\\x87\\xe0\\xa4\\x96\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa4\\xbf \\xe0\\xa4\\xb9\\xe0\\xa4\\xae\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\xb8\\xe0\\xa4\\x82\\xe0\\xa4\\xa4\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\x85\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9b\\xe0\\xa5\\x87 \\xe0\\xa4\\xb2\\xe0\\xa4\\x97\\xe0\\xa4\\xa4\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x97\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa4\\xb9 \\xe0\\xa4\\xac\\xe0\\xa4\\x9c \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae\\xe0\\xa5\\x8d\\xe0\\xa4\\xb9\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\x9c\\xe0\\xa5\\x80 \\xe0\\xa4\\x85\\xe0\\xa4\\xa7\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa4\\xaa\\xe0\\xa4\\x95 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82?'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x95\\xe0\\xa5\\x87\\xe0\\xa4\\x95 \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b\\xe0\\xa4\\x83 \\xe0\\xa4\\x9f\\xe0\\xa5\\x81\\xe0\\xa4\\x95\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc\\xe0\\xa5\\x8b \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\x9f \\xe0\\xa4\\x95\\xe0\\xa4\\xb0, \\xe0\\xa4\\xb9\\xe0\\xa4\\xb0 \\xe0\\xa4\\xac\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\x9f\\xe0\\xa5\\x81\\xe0\\xa4\\x95\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc\\xe0\\xa4\\xbe \\xe0\\xa4\\xa6\\xe0\\xa4\\xbf\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae \\xe0\\xa4\\x95\\xe0\\xa4\\xad\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xb8\\xe0\\xa5\\x80 \\xe0\\xa4\\xaa\\xe0\\xa4\\xb0\\xe0\\xa5\\x80\\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xb7\\xe0\\xa4\\xbe \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x85\\xe0\\xa4\\xb8\\xe0\\xa4\\xab\\xe0\\xa4\\xb2 \\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\x8f \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b?'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\x86\\xe0\\xa4\\xa0 \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2 \\xe0\\xa4\\x95\\xe0\\xa4\\xbe \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe \\xe0\\xa4\\x9c\\xe0\\xa4\\xac \\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x85\\xe0\\xa4\\xaa\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa4\\xbe\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe-\\xe0\\xa4\\xaa\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b\\xe0\\xa5\\x8b\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc \\xe0\\xa4\\xa6\\xe0\\xa4\\xbf\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\x9f\\xe0\\xa5\\x87\\xe0\\xa4\\xa8\\xe0\\xa4\\xbf\\xe0\\xa4\\xb8 \\xe0\\xa4\\xac\\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\xa4 \\xe0\\xa4\\x85\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9b\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa5\\x87\\xe0\\xa4\\xb2\\xe0\\xa4\\xa4\\xe0\\xa5\\x80 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\xac \\xe0\\xa4\\xaa\\xe0\\xa4\\xa2\\xe0\\xa4\\xbc \\xe0\\xa4\\xb0\\xe0\\xa4\\xb9\\xe0\\xa5\\x80 \\xe0\\xa4\\xb9\\xe0\\xa5\\x82\\xe0\\xa4\\x81\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa4\\xbf\\xe0\\xa4\\xb6 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xab\\xe0\\xa4\\x82\\xe0\\xa4\\xb8 \\xe0\\xa4\\x97\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe \\xe0\\xa4\\x94\\xe0\\xa4\\xb0 \\xe0\\xa4\\xa4\\xe0\\xa4\\xb0-\\xe0\\xa4\\xa4\\xe0\\xa4\\xb0 \\xe0\\xa4\\xad\\xe0\\xa5\\x80\\xe0\\xa4\\x97 \\xe0\\xa4\\x97\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xaf\\xe0\\xa4\\xb9 \\xe0\\xa4\\xae\\xe0\\xa4\\xb6\\xe0\\xa5\\x80\\xe0\\xa4\\xa8 \\xe0\\xa4\\x89\\xe0\\xa4\\xb8 \\xe0\\xa4\\xae\\xe0\\xa4\\xb6\\xe0\\xa5\\x80\\xe0\\xa4\\xa8 \\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\xac\\xe0\\xa5\\x87\\xe0\\xa4\\xb9\\xe0\\xa4\\xa4\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x86\\xe0\\xa4\\xa7\\xe0\\xa5\\x87 \\xe0\\xa4\\xb8\\xe0\\xa5\\x87\\xe0\\xa4\\xb5 \\xe0\\xa4\\xb8\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\x86\\xe0\\xa4\\x9c \\xe0\\xa4\\x95\\xe0\\xa5\\x81\\xe0\\xa4\\x9b \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xae\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8 \\xe0\\xa4\\x96\\xe0\\xa4\\xbc\\xe0\\xa4\\xb0\\xe0\\xa5\\x80\\xe0\\xa4\\xa6\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x9c\\xe0\\xa4\\xbe\\xe0\\xa4\\x8a\\xe0\\xa4\\x81\\xe0\\xa4\\x97\\xe0\\xa5\\x80\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x98\\xe0\\xa4\\xb0 \\xe0\\xa4\\x86\\xe0\\xa4\\x97 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\xaa\\xe0\\xa4\\x9f\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\x86 \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\xac \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa4\\xb0\\xe0\\xa5\\x80\\xe0\\xa4\\xa6\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe \\xe0\\xa4\\x9a\\xe0\\xa4\\xbe\\xe0\\xa4\\xb9\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x81\\xe0\\xa4\\x9d\\xe0\\xa5\\x87 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xac\\xe0\\xa5\\x8d\\xe0\\xa4\\xb2\\xe0\\xa4\\xa1\\xe0\\xa5\\x80 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x80 \\xe0\\xa4\\x9a\\xe0\\xa4\\xbe\\xe0\\xa4\\xb9\\xe0\\xa4\\xbf\\xe0\\xa4\\x8f\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb6 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa4\\xbe\\xe0\\xa4\\xb8 \\xe0\\xa4\\x94\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb8\\xe0\\xa4\\xae\\xe0\\xa4\\xaf \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae\\xe0\\xa5\\x8d\\xe0\\xa4\\xb9\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xa5 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xa4 \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\x8f\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa4\\xbe\\xe0\\xa4\\xaa\\xe0\\xa4\\xbe \\xe0\\xa4\\xac\\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\xa4 \\xe0\\xa4\\x85\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9b\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b\\xe0\\xa4\\x82 \\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa5\\x88\\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\xa2\\xe0\\xa5\\x82\\xe0\\xa4\\x81\\xe0\\xa4\\xa2\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\x8f \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc \\xe0\\xa4\\x95\\xe0\\xa5\\x80 \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa5\\x80 \\xe0\\xa4\\xa6\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x96\\xe0\\xa5\\x8b\\xe0\\xa4\\xb2 \\xe0\\xa4\\xa1\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x80\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x85\\xe0\\xa4\\xaa\\xe0\\xa4\\xa8\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa4\\xae\\xe0\\xa5\\x80\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc \\xe0\\xa4\\x89\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0 \\xe0\\xa4\\x95\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb2\\xe0\\xa5\\x87\\xe0\\xa4\\x9f \\xe0\\xa4\\x9c\\xe0\\xa4\\xbe\\xe0\\xa4\\x93\\xe0\\xa5\\xa4'], shape=(32,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for i, j in train_ds.take(1):\n",
        "    print('i: ',i)\n",
        "    print('j: ', j)\n",
        "    # print('j decoded: ',j.numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3DdjsaS4aqs"
      },
      "source": [
        "# Text Vectorization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZoplDkntjFxL"
      },
      "outputs": [],
      "source": [
        "output_sequence_length = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yZj0w70q0tne"
      },
      "outputs": [],
      "source": [
        "eng_vectorizer = tf.keras.layers.TextVectorization(standardize = tf_lower_and_split_punct_en, output_sequence_length= output_sequence_length)\n",
        "hin_vectorizer = tf.keras.layers.TextVectorization(standardize = tf_lower_and_split_punct_hi, output_sequence_length= output_sequence_length+1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lj-Y5ei_0tmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75873f83-c8fb-431d-fa99-2ec75e116b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "# Adapting to textvectorizer\n",
        "eng_vectorizer.adapt(train_ds.map(lambda x, y: x))\n",
        "hin_vectorizer.adapt(train_ds.map(lambda x, y: y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msq7v_jN0tkT",
        "outputId": "7c1550f1-0d65-4428-a258-9a281ce5659d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maxtokens:\n",
            "English :  2359\n",
            "Hindi:  3016\n"
          ]
        }
      ],
      "source": [
        "max_token_english = len(eng_vectorizer.get_vocabulary())\n",
        "max_token_hindi = len(hin_vectorizer.get_vocabulary())\n",
        "\n",
        "print('Maxtokens:')\n",
        "print( 'English : ', max_token_english)\n",
        "print('Hindi: ', max_token_hindi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBovvXnn0tjF",
        "outputId": "70baa11e-cd42-4b7c-da52-e33515044c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  उन्होंने मेरी का| मज़ाक उड़ाया\n",
            "\n",
            "Encoded text: ,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(201,), dtype=int64, numpy=\n",
              "array([   2,  173,   40,   20, 1446,  369,    1,    3,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "print('Text: ',some_hindi_text)\n",
        "print('\\nEncoded text: ,')\n",
        "hin_vectorizer(some_hindi_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM2zCVr60tgA"
      },
      "source": [
        "## Mapping Vectorizer to dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fTsnsCVwjFxP"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5UvErrnz0teP"
      },
      "outputs": [],
      "source": [
        "def make_vec(x, y ):\n",
        "    x, y = eng_vectorizer(x), hin_vectorizer(y)\n",
        "\n",
        "    y_in = y[:,:-1]\n",
        "    y_out = y[:,1:]\n",
        "    return (x,y_in), y_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2TtoPhnZ0tc7"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(make_vec) #.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(make_vec) # .batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6qd2-dCQjFxR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6BTOBm3i0tbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f6542a-f959-4e83-d1b3-11b8af9ab362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  2  39 332 ...   0   0   0]\n",
            " [  2   8 183 ...   0   0   0]\n",
            " [  2  11   8 ...   0   0   0]\n",
            " ...\n",
            " [  2  26 827 ...   0   0   0]\n",
            " [  2   9   1 ...   0   0   0]\n",
            " [  2   8 360 ...   0   0   0]], shape=(32, 200), dtype=int64)\n",
            "\n",
            "tf.Tensor(\n",
            "[[ 39 332  15 ...   0   0   0]\n",
            " [  8 183 141 ...   0   0   0]\n",
            " [ 11   8 168 ...   0   0   0]\n",
            " ...\n",
            " [ 26 827  20 ...   0   0   0]\n",
            " [  9   1  90 ...   0   0   0]\n",
            " [  8 360 949 ...   0   0   0]], shape=(32, 200), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for i,j in val_ds.take(1):\n",
        "    print(i[1])\n",
        "    print()\n",
        "    print(j)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkUCiddP0tRf"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYUlG5J1jFxT"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Tt4J-fOx0tP5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, text_processor, units, embedding_dims = 32):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.units = units\n",
        "        # self.return_state = return_state\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units, mask_zero=True)\n",
        "\n",
        "        # The RNN layer processes those vectors sequentially.\n",
        "        self.rnn = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='sum',\n",
        "            layer=tf.keras.layers.LSTM(units, \n",
        "                                       return_sequences = True, \n",
        "                                       return_state = True,\n",
        "                                       recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        # 2. The embedding layer looks up the embedding vector for each token.\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # 3. The GRU processes the sequence of embeddings.\n",
        "        *x, state_h, state_c = self.rnn(x)\n",
        "        tf.print('after encoder return sequence true: ',len(x) )\n",
        "        state = [state_h, state_c]\n",
        "    \n",
        "        return x, state\n",
        "\n",
        "    def convert_input(self, texts):\n",
        "        texts = tf.convert_to_tensor(texts)\n",
        "        if len(texts.shape) == 0:\n",
        "            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "        context = self.text_processor(texts)\n",
        "        context = self(context)\n",
        "        return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_LCPt7qjFxU"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BsaIPmwK0tOQ"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, x, context):\n",
        "\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=x,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "\n",
        "        # Cache the attention scores for plotting later.\n",
        "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "        self.last_attention_weights = attn_scores\n",
        "\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PM0TckqjFxV"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9mOtgmJw0tMk"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, text_processor, units, embedding_dims = 32):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.word_to_id = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "        self.id_to_word = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n",
        "        self.start_token = self.word_to_id('[START]')\n",
        "        self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "\n",
        "        # 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units, mask_zero=True)\n",
        "\n",
        "        # 2. The RNN keeps track of what's been generated so far.\n",
        "        self.rnn = tf.keras.layers.LSTM(units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttention(units)\n",
        "\n",
        "        # 4. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Rix8TVjFxX"
      },
      "source": [
        "### Decoder call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7vLwbSZi0tK3"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "\n",
        "    # 1. Lookup the embeddings\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # 2. Process the target sequence.\n",
        "    x = self.rnn(x, initial_state=state)\n",
        "    tf.print('decoder output: ', len(x))\n",
        "    # 3. Use the RNN output as the query for the attention over the context.\n",
        "    x = self.attention(x, context)\n",
        "    self.last_attention_weights = self.attention.last_attention_weights\n",
        "\n",
        "\n",
        "    # Step 4. Generate logit predictions for the next token.\n",
        "    logits = self.output_layer(x)\n",
        "\n",
        "    if return_state:\n",
        "        return logits, state\n",
        "    else:\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6rWI_DmA0tJB"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "    batch_size = tf.shape(context)[0]\n",
        "    start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "    embedded = self.embedding(start_tokens)\n",
        "    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CmQFKqTV0tHT"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "    words = self.id_to_word(tokens)\n",
        "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VtcX4VA00tFx"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "    logits, state = self(context, next_token, state = state, return_state=True) \n",
        "\n",
        "    if temperature == 0.0:\n",
        "        next_token = tf.argmax(logits, axis=-1)\n",
        "    else:\n",
        "        logits = logits[:, -1, :]/temperature\n",
        "        next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (next_token == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "    return next_token, done, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QbTvfGlI0tCK",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# class Translator(tf.keras.Model):\n",
        "#     @classmethod\n",
        "#     def add_method(cls, fun):\n",
        "#         setattr(cls, fun.__name__, fun)\n",
        "#         return fun\n",
        "\n",
        "#     def __init__(self, units, context_text_processor, target_text_processor):\n",
        "#         super().__init__()\n",
        "#         # Build the encoder and decoder\n",
        "#         encoder = Encoder(context_text_processor, units)\n",
        "#         decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "        \n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         context, x = inputs\n",
        "#         tf.print('Before encoder-decoder')\n",
        "#         # tf.print('inputs : ',inputs.shape)\n",
        "#         tf.print('context: ',context.shape)\n",
        "#         tf.print('x      : ',x.shape)\n",
        "#         context = self.encoder(context)\n",
        "#         tf.print()\n",
        "#         logits = self.decoder(context, x)\n",
        "#         tf.print('--'*20)\n",
        "#         tf.print('After encoder-decoder')\n",
        "#         tf.print('context: ',context.shape)\n",
        "#         tf.print('logits : ',logits.shape)\n",
        "#     #TODO(b/250038731): remove this\n",
        "#         try:\n",
        "#           # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "#             del logits._keras_mask\n",
        "#         except AttributeError:\n",
        "#             pass\n",
        "\n",
        "#         return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "w0JH_eH3jFxc"
      },
      "outputs": [],
      "source": [
        "class Translator2(tf.keras.Model):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, units, context_text_processor, target_text_processor):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.context_text_processor = context_text_processor\n",
        "        self.target_text_processor = target_text_processor\n",
        "\n",
        "        self.context_vocab_size = context_text_processor.vocabulary_size()\n",
        "        self.target_vocab_size = target_text_processor.vocabulary_size()\n",
        "        \n",
        "        self.word_to_id = tf.keras.layers.StringLookup(vocabulary=target_text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "        self.id_to_word = tf.keras.layers.StringLookup(vocabulary=target_text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n",
        "    \n",
        "        self.units = units\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding1 = tf.keras.layers.Embedding(self.context_vocab_size, units, mask_zero=True)\n",
        "        self.embedding2 = tf.keras.layers.Embedding(self.target_vocab_size, units, mask_zero=True)\n",
        "\n",
        "        # The RNN layer processes those vectors sequentially.\n",
        "        self.encoder = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='concat',\n",
        "            layer=tf.keras.layers.GRU(units, \n",
        "                                       return_sequences = True, \n",
        "                                       return_state = True,\n",
        "                                       recurrent_initializer='glorot_uniform'))\n",
        "        \n",
        "        self.decoder = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='concat',\n",
        "            layer=tf.keras.layers.GRU(units, \n",
        "                                       return_sequences = True, \n",
        "                                       return_state = True,\n",
        "                                       recurrent_initializer='glorot_uniform'))\n",
        "        \n",
        "        \n",
        "        self.start_token = self.word_to_id('[START]')\n",
        "        self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "        # 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttention(units)\n",
        "        self.last_attention_weights = None\n",
        "        # 4. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.output_layer = tf.keras.layers.Dense(self.target_vocab_size)\n",
        "        \n",
        "        self.encoder_state = None\n",
        "    def call(self, X, y=None):\n",
        "        context, que = X\n",
        "        \n",
        "        #Encoding\n",
        "        # 1. embedding\n",
        "        x = self.embedding1(context)\n",
        "        # tf.print('after embedding: x shape: ',x.shape )\n",
        "        encoder_context, enc_h, enc_c = self.encoder(x)\n",
        "        self.encoder_state = [enc_h, enc_c]\n",
        "        # tf.print('after encodeing: x shape: ',len(x) )\n",
        "\n",
        "        # encoder_context, encoder_state = x\n",
        "        #Decoding\n",
        "        x = self.embedding2(que)\n",
        "        decoder_context, decoder_state_h, decoder_state_c = self.decoder(x, initial_state=self.encoder_state)\n",
        "        \n",
        "        x = self.attention(decoder_context, encoder_context)\n",
        "        # self.last_attention_weights = self.attention.last_attention_weights\n",
        "        # tf.print('decoder context shape: ', len(decoder_context))\n",
        "        # logits\n",
        "        logits = self.output_layer(x)\n",
        "            # tf.print('\\n')\n",
        "        #TODO(b/250038731): remove this\n",
        "        try:\n",
        "          # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def convert_input(self, texts):\n",
        "\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "        texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.context_text_processor(texts)\n",
        "    context = self(context)\n",
        "    return context"
      ],
      "metadata": {
        "id": "IXzwfGpMpU3G"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding2(start_tokens)\n",
        "  context = self.decoder.get_initial_state(embedded)[0]\n",
        "  return start_tokens, done, context "
      ],
      "metadata": {
        "id": "E-FOjbqi6aDM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ],
      "metadata": {
        "id": "XYldFggti6nm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self.decoder(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ],
      "metadata": {
        "id": "Utdr6bkrk8Vb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def translate(self,\n",
        "              texts,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "    context = self.convert_input(texts)\n",
        "    batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "    tokens = []\n",
        "    # attention_weights = []\n",
        "    next_token, done, state = self.get_initial_state(context)\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Generate the next token\n",
        "        next_token, done, state = self.get_next_token(context, next_token, done,  state, temperature)\n",
        "\n",
        "        # Collect the generated tokens\n",
        "        tokens.append(next_token)\n",
        "        # attention_weights.append(self.last_attention_weights)\n",
        "\n",
        "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "            break\n",
        "\n",
        "    # Stack the lists of tokens and attention weights.\n",
        "    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "    # self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "    result = self.decoder.tokens_to_text(tokens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "Di7FvIMLpEVZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = model.translate(['She loves me'])\n",
        "ss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "fNCLmMr_sfW-",
        "outputId": "82b5824e-ec53-4b79-94de-9c2affd012ee"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-5118fff0d73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'She loves me'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-0aa28810070f>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, texts, max_length, temperature)\u001b[0m\n\u001b[1;32m      5\u001b[0m               temperature=0.0):\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Process the input texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-ee0864b58104>\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_text_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-7e94b26da886>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mque\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'translator2' (type Translator2).\n\nnot enough values to unpack (expected 2, got 1)\n\nCall arguments received by layer 'translator2' (type Translator2):\n  • X=tf.Tensor(shape=(1, 200), dtype=int64)\n  • y=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "lhj-jdpS0tAI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = Translator2(UNITS, eng_vectorizer, hin_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "dSxxNTtT0s2z",
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# sample = train_df.sample(5)\n",
        "# some_hindi_text = sample['hindi'].to_numpy()\n",
        "# some_eng_text = sample['english'].to_numpy()\n",
        "\n",
        "# print(some_hindi_text)\n",
        "# print(some_eng_text)\n",
        "\n",
        "# vectorized_eng_text = eng_vectorizer(some_eng_text)\n",
        "# vectorized_eng_text[:,:10]\n",
        "\n",
        "# vectorized_hindi_text = hin_vectorizer(some_hindi_text)\n",
        "# vectorized_hindi_text[:,:10]\n",
        "\n",
        "# vec_hindi_in = vectorized_hindi_text[:,:-1]\n",
        "# vec_hindi_out = vectorized_hindi_text[:,1:]\n",
        "# print(vec_hindi_in[:,:10])\n",
        "# print()\n",
        "# print(vec_hindi_out[:,:10])\n",
        "\n",
        "# encoder = Encoder(eng_vectorizer, UNITS)\n",
        "# # context_eng = encoder((vectorized_eng_text))\n",
        "\n",
        "# new_tx = encoder.convert_input(['hey man'])\n",
        "\n",
        "# # context_eng\n",
        "\n",
        "# # decoder = Decoder(hin_vectorizer, UNITS)\n",
        "# # logits = decoder(context_eng, vec_hindi_in)\n",
        "# # logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5DMM5XHX0syX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wrQnQhGM0stC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "IGw3VSmG0sqa"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YacbS2vjjFxg"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-i_XW14UjFxg"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "nQ5eDngHjFxh"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30\n",
        "CKPT_DIR = './model_checkpoint'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mw84m4ZTjFxh"
      },
      "outputs": [],
      "source": [
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(CKPT_DIR,  f\"{datetime.now().strftime('%m:%d:%Y, %H:%M:%S')}\"),\n",
        "    monitor= 'loss',\n",
        "    verbose= 0,\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True,\n",
        "    mode= 'auto',\n",
        "    save_freq='epoch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tqtKPvmAjFxi"
      },
      "outputs": [],
      "source": [
        "data_amount = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rg1ZWQV90sn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a780c3-a7d6-4957-e280-d5006e308865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "60/60 [==============================] - 41s 254ms/step - loss: 6.7381 - masked_acc: 0.1199 - masked_loss: 6.7381 - val_loss: 6.1761 - val_masked_acc: 0.1210 - val_masked_loss: 6.1694\n",
            "Epoch 2/30\n",
            "60/60 [==============================] - 7s 123ms/step - loss: 5.7408 - masked_acc: 0.1472 - masked_loss: 5.7366 - val_loss: 5.5941 - val_masked_acc: 0.1976 - val_masked_loss: 5.5964\n",
            "Epoch 3/30\n",
            "60/60 [==============================] - 4s 70ms/step - loss: 5.0454 - masked_acc: 0.2503 - masked_loss: 5.0392 - val_loss: 4.9558 - val_masked_acc: 0.3056 - val_masked_loss: 4.9578\n",
            "Epoch 4/30\n",
            "60/60 [==============================] - 3s 55ms/step - loss: 4.2901 - masked_acc: 0.3585 - masked_loss: 4.2901 - val_loss: 4.3521 - val_masked_acc: 0.3768 - val_masked_loss: 4.3530\n",
            "Epoch 5/30\n",
            "60/60 [==============================] - 3s 56ms/step - loss: 3.6373 - masked_acc: 0.4384 - masked_loss: 3.6372 - val_loss: 3.8181 - val_masked_acc: 0.4346 - val_masked_loss: 3.8285\n",
            "Epoch 6/30\n",
            "60/60 [==============================] - 4s 62ms/step - loss: 3.1468 - masked_acc: 0.4927 - masked_loss: 3.1597 - val_loss: 3.3584 - val_masked_acc: 0.4811 - val_masked_loss: 3.3523\n",
            "Epoch 7/30\n",
            "60/60 [==============================] - 3s 45ms/step - loss: 2.6158 - masked_acc: 0.5629 - masked_loss: 2.6158 - val_loss: 3.0064 - val_masked_acc: 0.5636 - val_masked_loss: 2.9967\n",
            "Epoch 8/30\n",
            "60/60 [==============================] - 3s 49ms/step - loss: 2.2180 - masked_acc: 0.6310 - masked_loss: 2.2129 - val_loss: 2.7001 - val_masked_acc: 0.6224 - val_masked_loss: 2.6862\n",
            "Epoch 9/30\n",
            "60/60 [==============================] - 5s 81ms/step - loss: 1.9225 - masked_acc: 0.6752 - masked_loss: 1.9329 - val_loss: 2.4203 - val_masked_acc: 0.6783 - val_masked_loss: 2.4108\n",
            "Epoch 10/30\n",
            "60/60 [==============================] - 4s 60ms/step - loss: 1.5534 - masked_acc: 0.7438 - masked_loss: 1.5534 - val_loss: 2.2264 - val_masked_acc: 0.6984 - val_masked_loss: 2.2332\n",
            "Epoch 11/30\n",
            "60/60 [==============================] - 3s 48ms/step - loss: 1.3211 - masked_acc: 0.7948 - masked_loss: 1.3154 - val_loss: 2.0234 - val_masked_acc: 0.7444 - val_masked_loss: 2.0210\n",
            "Epoch 12/30\n",
            "60/60 [==============================] - 3s 45ms/step - loss: 1.1233 - masked_acc: 0.8255 - masked_loss: 1.1339 - val_loss: 1.8815 - val_masked_acc: 0.7736 - val_masked_loss: 1.8816\n",
            "Epoch 13/30\n",
            "60/60 [==============================] - 3s 58ms/step - loss: 0.8886 - masked_acc: 0.8850 - masked_loss: 0.8886 - val_loss: 1.7497 - val_masked_acc: 0.7913 - val_masked_loss: 1.7605\n",
            "Epoch 14/30\n",
            "60/60 [==============================] - 3s 49ms/step - loss: 0.7373 - masked_acc: 0.9145 - masked_loss: 0.7345 - val_loss: 1.6510 - val_masked_acc: 0.8101 - val_masked_loss: 1.6563\n",
            "Epoch 15/30\n",
            "60/60 [==============================] - 3s 47ms/step - loss: 0.6270 - masked_acc: 0.9350 - masked_loss: 0.6197 - val_loss: 1.5620 - val_masked_acc: 0.8267 - val_masked_loss: 1.5746\n",
            "Epoch 16/30\n",
            "60/60 [==============================] - 3s 54ms/step - loss: 0.4689 - masked_acc: 0.9722 - masked_loss: 0.4689 - val_loss: 1.6132 - val_masked_acc: 0.8210 - val_masked_loss: 1.6003\n",
            "Epoch 17/30\n",
            "60/60 [==============================] - 4s 64ms/step - loss: 0.3880 - masked_acc: 0.9827 - masked_loss: 0.3832 - val_loss: 1.5571 - val_masked_acc: 0.8295 - val_masked_loss: 1.5580\n",
            "Epoch 18/30\n",
            "60/60 [==============================] - 3s 47ms/step - loss: 0.3235 - masked_acc: 0.9896 - masked_loss: 0.3288 - val_loss: 1.5560 - val_masked_acc: 0.8301 - val_masked_loss: 1.5536\n",
            "Epoch 19/30\n",
            "60/60 [==============================] - 3s 45ms/step - loss: 0.2269 - masked_acc: 0.9978 - masked_loss: 0.2269 - val_loss: 1.4934 - val_masked_acc: 0.8388 - val_masked_loss: 1.4989\n",
            "Epoch 20/30\n",
            "60/60 [==============================] - 3s 50ms/step - loss: 0.1876 - masked_acc: 0.9989 - masked_loss: 0.1854 - val_loss: 1.4341 - val_masked_acc: 0.8443 - val_masked_loss: 1.4399\n",
            "Epoch 21/30\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.1546 - masked_acc: 0.9991 - masked_loss: 0.1568 - val_loss: 1.5120 - val_masked_acc: 0.8384 - val_masked_loss: 1.5186\n",
            "Epoch 22/30\n",
            "60/60 [==============================] - 3s 45ms/step - loss: 0.1075 - masked_acc: 0.9998 - masked_loss: 0.1075 - val_loss: 1.4428 - val_masked_acc: 0.8532 - val_masked_loss: 1.4309\n",
            "Epoch 23/30\n",
            "60/60 [==============================] - 3s 49ms/step - loss: 0.0932 - masked_acc: 0.9996 - masked_loss: 0.0933 - val_loss: 1.4524 - val_masked_acc: 0.8484 - val_masked_loss: 1.4336\n",
            "Epoch 24/30\n",
            "60/60 [==============================] - 3s 44ms/step - loss: 0.0754 - masked_acc: 0.9999 - masked_loss: 0.0760 - val_loss: 1.4654 - val_masked_acc: 0.8451 - val_masked_loss: 1.4477\n",
            "Epoch 25/30\n",
            "60/60 [==============================] - 4s 60ms/step - loss: 0.0584 - masked_acc: 0.9999 - masked_loss: 0.0584 - val_loss: 1.4987 - val_masked_acc: 0.8456 - val_masked_loss: 1.5155\n",
            "Epoch 26/30\n",
            "60/60 [==============================] - 3s 44ms/step - loss: 0.0507 - masked_acc: 0.9999 - masked_loss: 0.0504 - val_loss: 1.4257 - val_masked_acc: 0.8514 - val_masked_loss: 1.4332\n",
            "Epoch 27/30\n",
            "60/60 [==============================] - 3s 43ms/step - loss: 0.0450 - masked_acc: 0.9998 - masked_loss: 0.0444 - val_loss: 1.4273 - val_masked_acc: 0.8546 - val_masked_loss: 1.4238\n",
            "Epoch 28/30\n",
            "60/60 [==============================] - 3s 44ms/step - loss: 0.0367 - masked_acc: 0.9998 - masked_loss: 0.0367 - val_loss: 1.4593 - val_masked_acc: 0.8508 - val_masked_loss: 1.4511\n",
            "Epoch 29/30\n",
            "60/60 [==============================] - 4s 62ms/step - loss: 0.0332 - masked_acc: 1.0000 - masked_loss: 0.0330 - val_loss: 1.5142 - val_masked_acc: 0.8446 - val_masked_loss: 1.5054\n",
            "Epoch 30/30\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.0300 - masked_acc: 0.9999 - masked_loss: 0.0300 - val_loss: 1.4756 - val_masked_acc: 0.8493 - val_masked_loss: 1.4712\n"
          ]
        }
      ],
      "source": [
        "# tf.executing_eagerly(False)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch = int(data_amount*(len(train_ds)/EPOCHS)),\n",
        "\n",
        "    validation_data=val_ds.repeat(),\n",
        "    validation_steps = 5,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor = 'masked_loss', patience=3),\n",
        "    model_ckpt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0oAu_jN60slV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "243dd6f2-7c99-4f23-bdf0-b6c59ae0775c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa03e607640>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "# plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "XUF3LXpN0sjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "037fe6a6-81d6-4aef-a74f-939a8a9ccb81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa03fadde80>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "# plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbmAh9W70sgO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDETfmnw0sdp"
      },
      "outputs": [],
      "source": [
        "result = model.translate(['She loves me']) \n",
        "result[0].numpy().decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty6op_uUjFxl"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.title('accuracy vs epochs')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfnUjWD_jFxl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}