{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tikendraw/language-translation-model/blob/main/language_translation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1hJ48ytxM3b"
      },
      "source": [
        "# Language Translation Model (English to Hindi)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrmDJdXC9SfD",
        "outputId": "c2114be3-b537-469e-d712-ec9989442da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'language-translation-model'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 19 (delta 6), reused 12 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), 343.08 KiB | 1.19 MiB/s, done.\n",
            "/content/language-translation-model\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    \n",
        "    ! git clone https://github.com/tikendraw/language-translation-model.git \n",
        "    os.chdir('language-translation-model') \n",
        "    print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cxy3JvX9Fw4",
        "outputId": "122d4ad1-7820-4b37-ec41-7891adde7695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTf version:  2.11.0\n",
            "GPU:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "! pip install polars -q\n",
        "import polars as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model , optimizers\n",
        "from tensorflow.keras.layers import Attention,GRU, LSTM, Bidirectional, Dense, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, AveragePooling1D, Dropout, concatenate, Concatenate\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install tensorflow_hub -q\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print('Tf version: ',tf.__version__)\n",
        "print('GPU: ', is_gpu:=len(tf.config.list_physical_devices('GPU')))\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "os.environ[\"TFHUB_CACHE_DIR\"] = './tmp/tfhub'\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
        "None\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "if is_gpu:\n",
        "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "    config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(physical_devices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nY49Vs8mxGcD"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'http://www.manythings.org/anki/hin-eng.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7P06oG8xiS7",
        "outputId": "ceaf1fc4-62f4-422b-91f2-c9fcc79c05f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-20 07:00:24--  http://www.manythings.org/anki/hin-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131711 (129K) [application/zip]\n",
            "Saving to: ‘dataset/hin-eng.zip.1’\n",
            "\n",
            "hin-eng.zip.1       100%[===================>] 128.62K   302KB/s    in 0.4s    \n",
            "\n",
            "2023-02-20 07:00:25 (302 KB/s) - ‘dataset/hin-eng.zip.1’ saved [131711/131711]\n",
            "\n",
            "Archive:  ./dataset/hin-eng.zip\n",
            "replace ./dataset/hin.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "828K\t./dataset\n"
          ]
        }
      ],
      "source": [
        "# # # Download the dataset\n",
        "# if 'google.colab' in sys.modules:\n",
        "#     # donwload\n",
        "#     !wget $dataset_url -P dataset\n",
        "\n",
        "#     # # Unzip the downloaded file\n",
        "#     !unzip ./dataset/hin-eng.zip -d ./dataset\n",
        "\n",
        "#     # # Show size\n",
        "#     !du -h  ./dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITptJktjzLho"
      },
      "source": [
        "# Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4XP6M5Eb0t5F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vraPNhwl0t2Z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./dataset/hin.txt', sep = '\\t', new_columns = ['english', 'hindi', 'somethingelse'])[['english','hindi']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsHrOgJX0t0m",
        "outputId": "8eed1347-6fc7-4d37-8e14-4c30d59677b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2908, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "_iYNVAyD0tyx",
        "outputId": "68719368-eb2e-4de0-fc9c-4052d807ce91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 2)\n",
              "┌─────────────────────────────────────┬─────────────────────────────────┐\n",
              "│ english                             ┆ hindi                           │\n",
              "│ ---                                 ┆ ---                             │\n",
              "│ str                                 ┆ str                             │\n",
              "╞═════════════════════════════════════╪═════════════════════════════════╡\n",
              "│ These are our books.                ┆ ये हमारी किताबें हैं।                │\n",
              "│ I am not from India.                ┆ मैं भारत से नहीं हूँ।                 │\n",
              "│ Well, what're you waiting for?      ┆ खैर, आप किसका इंतज़ार कर रहे हैं...   │\n",
              "│ Why didn't you go to the office?    ┆ तुम दफ़्तर क्यों नहीं गए?             │\n",
              "│ ...                                 ┆ ...                             │\n",
              "│ I've never met such a kind man.     ┆ मैं कभी भी इतने दयालु व्यक्ति से...    │\n",
              "│ He cried as if he were a boy of ... ┆ उसने छः बरस के बच्चे की तरह रोया... │\n",
              "│ I don't know what Tom knows.        ┆ मुझे नहीं पता कि टॉम को क्या पता... │\n",
              "│ It is necessary for you to see a... ┆ तुम्हें जल्द-से-जल्द डॉक्टर के प...      │\n",
              "└─────────────────────────────────────┴─────────────────────────────────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style>\n",
              ".pl-dataframe > thead > tr > th {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "\n",
              "<table border=\"1\" class=\"dataframe pl-dataframe\">\n",
              "<small>shape: (10, 2)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "english\n",
              "</th>\n",
              "<th>\n",
              "hindi\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;These are our ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;ये हमारी किताब...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;I am not from ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;मैं भारत से नह...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;Well, what&#x27;re ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;खैर, आप किसका ...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;Why didn&#x27;t you...\n",
              "</td>\n",
              "<td>\n",
              "&quot;तुम दफ़्तर क्य...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;I&#x27;m really tir...\n",
              "</td>\n",
              "<td>\n",
              "&quot;मैं बहुत थक गय...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;His shoes were...\n",
              "</td>\n",
              "<td>\n",
              "&quot;उसके जूते इतने...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;I&#x27;ve never met...\n",
              "</td>\n",
              "<td>\n",
              "&quot;मैं कभी भी इतन...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;He cried as if...\n",
              "</td>\n",
              "<td>\n",
              "&quot;उसने छः बरस के...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;I don&#x27;t know w...\n",
              "</td>\n",
              "<td>\n",
              "&quot;मुझे नहीं पता ...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "&quot;It is necessar...\n",
              "</td>\n",
              "<td>\n",
              "&quot;तुम्हें जल्द-स...\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "swlPFpr-0txP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BDxEUwx2jFxB"
      },
      "outputs": [],
      "source": [
        "UNITS = 32\n",
        "EMBEDDING_DIMS = 16\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceSkRUmM0twM"
      },
      "source": [
        "# Prepare the data `tf.data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BCw6ZgqV0tuW"
      },
      "outputs": [],
      "source": [
        "# Split the data for train and val\n",
        "train_df, val_df = train_test_split(df, test_size = .02, random_state = 4 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA0bZi7Z0ttP",
        "outputId": "398d1ec4-58e3-464f-93c5-de631142f22f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape:  (2849, 2)\n",
            "val shape:  (59, 2)\n"
          ]
        }
      ],
      "source": [
        "print('train shape: ', train_df.shape)\n",
        "print('val shape: ', val_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z5rNSvh2jFxE"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "puSucMUn0tq-"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df['english'].to_list(), train_df['hindi'].to_list())).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_df['english'].to_list(), val_df['hindi'].to_list())).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RqH0xQMUjFxG",
        "outputId": "c85c912a-1e8c-4c64-bf70-89cd5cac81a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_APB0Ah64b26"
      },
      "outputs": [],
      "source": [
        "\n",
        "# preprocessing text\n",
        "def tf_lower_and_split_punct_en(text):\n",
        "    # Split accented characters.\n",
        "    # text = tf.text.normalize_utf8(text, 'NFKD')\n",
        "    text = tf.strings.lower(text)\n",
        "    # Keep space, a to z, and select punctuation.\n",
        "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "    # Add spaces around punctuation.\n",
        "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
        "    # Strip whitespace.\n",
        "    text = tf.strings.strip(text)\n",
        "\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# preprocessing text\n",
        "def tf_lower_and_split_punct_hi(text):\n",
        "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfNyTkJ56pPt",
        "outputId": "f69ea8c3-7239-4b0d-e0e7-483d82f2c7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "उन्होंने मेरी का| मज़ाक उड़ाया\n",
            "tf.Tensor(b'[START] \\xe0\\xa4\\x89\\xe0\\xa4\\xa8\\xe0\\xa5\\x8d\\xe0\\xa4\\xb9\\xe0\\xa5\\x8b\\xe0\\xa4\\x82\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa4\\xbe |  \\xe0\\xa4\\xae\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc\\xe0\\xa4\\xbe\\xe0\\xa4\\x95 \\xe0\\xa4\\x89\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc\\xe0\\xa4\\xbe\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe [END]', shape=(), dtype=string)\n",
            "[START] उन्होंने मेरी का |  मज़ाक उड़ाया [END]\n"
          ]
        }
      ],
      "source": [
        "some_hindi_text = 'उन्होंने मेरी का| मज़ाक उड़ाया'\n",
        "print(some_hindi_text)\n",
        "b= tf_lower_and_split_punct_hi(some_hindi_text)\n",
        "print(b)\n",
        "print(b.numpy().decode())\n",
        "del(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRZEds9s0tpU",
        "outputId": "88d0d644-5f2f-495e-e03b-b18741185edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:  tf.Tensor(\n",
            "[b'This is the very book that I wanted to read.'\n",
            " b\"I'm looking for an old man.\" b'My uncle is an amateur cricket player.'\n",
            " b'He turned traitor.' b'A thick mist covered the countryside.'\n",
            " b'Some fish fly.' b'Water is very important.'\n",
            " b'His new book is going to come out next month.'\n",
            " b\"I've been given until tomorrow to finish this.\"\n",
            " b'Do you go there by bus or by car?' b\"You should've seen the movie.\"\n",
            " b'She died yesterday afternoon.' b'Would you mind if I smoke?'\n",
            " b'Take this medicine every six hours.' b'I actually have to do that.'\n",
            " b'I hate taking risks.' b'The storm destroyed the whole town.'\n",
            " b'He has his hair cut once a month.'\n",
            " b'He ought to have made allowances for his age.'\n",
            " b'She is a wealthy woman.' b'I have a bone to pick with you.'\n",
            " b'I was able to win the first prize.'\n",
            " b'He exhibited no remorse for his crime.'\n",
            " b\"You're doing very well. Keep it up.\" b'Each of them has a bicycle.'\n",
            " b'Do you believe in God?'\n",
            " b\"I was searching for something that didn't exist.\"\n",
            " b'I lost consciousness.' b'Look up the phrase in your dictionary.'\n",
            " b'Tom talks a lot about his father.' b'I can read English.'\n",
            " b'The rumor turned out to be true.'], shape=(32,), dtype=string)\n",
            "j:  tf.Tensor(\n",
            "[b'\\xe0\\xa4\\xaf\\xe0\\xa4\\xb9 \\xe0\\xa4\\xb5\\xe0\\xa4\\xb9\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\xac \\xe0\\xa4\\xb9\\xe0\\xa5\\x88 \\xe0\\xa4\\x9c\\xe0\\xa4\\xbf\\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\xaa\\xe0\\xa4\\xa2\\xe0\\xa4\\xbc\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe \\xe0\\xa4\\x9a\\xe0\\xa4\\xbe\\xe0\\xa4\\xb9\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xac\\xe0\\xa5\\x82\\xe0\\xa4\\xa2\\xe0\\xa4\\xbc\\xe0\\xa5\\x87 \\xe0\\xa4\\x86\\xe0\\xa4\\xa6\\xe0\\xa4\\xae\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa5\\x80 \\xe0\\xa4\\xa4\\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xb6 \\xe0\\xa4\\xae\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x82\\xe0\\xa4\\x81\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\x85\\xe0\\xa4\\x82\\xe0\\xa4\\x95\\xe0\\xa4\\xb2 \\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa4\\xbf\\xe0\\xa4\\x95\\xe0\\xa5\\x87\\xe0\\xa4\\x9f \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xb6\\xe0\\xa5\\x8c\\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc\\xe0\\xa5\\x80 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\xa6\\xe0\\xa5\\x87\\xe0\\xa4\\xb6\\xe0\\xa4\\xa6\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b\\xe0\\xa4\\xb9\\xe0\\xa5\\x80 \\xe0\\xa4\\xac\\xe0\\xa4\\xa8 \\xe0\\xa4\\x97\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\x81\\xe0\\xa4\\xb5 \\xe0\\xa4\\xaa\\xe0\\xa4\\xb0 \\xe0\\xa4\\x97\\xe0\\xa4\\xb9\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa5\\x8b\\xe0\\xa4\\xb9\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe \\xe0\\xa4\\x9b\\xe0\\xa4\\xbe \\xe0\\xa4\\x97\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x95\\xe0\\xa5\\x81\\xe0\\xa4\\x9b \\xe0\\xa4\\xae\\xe0\\xa4\\x9b\\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa4\\x81 \\xe0\\xa4\\x89\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc \\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa4\\xa4\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xaa\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8\\xe0\\xa5\\x80 \\xe0\\xa4\\xac\\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\xa4 \\xe0\\xa4\\x9c\\xe0\\xa4\\xb0\\xe0\\xa5\\x82\\xe0\\xa4\\xb0\\xe0\\xa5\\x80 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa5\\x80 \\xe0\\xa4\\xa8\\xe0\\xa4\\x88 \\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\xac \\xe0\\xa4\\x85\\xe0\\xa4\\x97\\xe0\\xa4\\xb2\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\x9b\\xe0\\xa4\\xaa\\xe0\\xa5\\x87\\xe0\\xa4\\x97\\xe0\\xa5\\x80\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x81\\xe0\\xa4\\x9d\\xe0\\xa5\\x87 \\xe0\\xa4\\xaf\\xe0\\xa5\\x87 \\xe0\\xa4\\x95\\xe0\\xa4\\xb2 \\xe0\\xa4\\xa4\\xe0\\xa4\\x95 \\xe0\\xa4\\x96\\xe0\\xa4\\xa4\\xe0\\xa4\\xae \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x88 \\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae \\xe0\\xa4\\xb5\\xe0\\xa4\\xb9\\xe0\\xa4\\xbe\\xe0\\xa4\\x81 \\xe0\\xa4\\xac\\xe0\\xa4\\xb8 \\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\x9c\\xe0\\xa4\\xbe\\xe0\\xa4\\xa4\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b \\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\xa1\\xe0\\xa4\\xbc\\xe0\\xa5\\x80 \\xe0\\xa4\\xb8\\xe0\\xa5\\x87?'\n",
            " b'\\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae\\xe0\\xa5\\x8d\\xe0\\xa4\\xb9\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xab\\xe0\\xa4\\xbc\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2\\xe0\\xa5\\x8d\\xe0\\xa4\\xae \\xe0\\xa4\\xa6\\xe0\\xa5\\x87\\xe0\\xa4\\x96\\xe0\\xa4\\xa8\\xe0\\xa5\\x80 \\xe0\\xa4\\x9a\\xe0\\xa4\\xb9\\xe0\\xa4\\xbf\\xe0\\xa4\\x8f \\xe0\\xa4\\xa5\\xe0\\xa5\\x80\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xa8\\xe0\\xa4\\x95\\xe0\\xa5\\x80 \\xe0\\xa4\\xae\\xe0\\xa5\\x8c\\xe0\\xa4\\xa4 \\xe0\\xa4\\x95\\xe0\\xa4\\xb2 \\xe0\\xa4\\xa6\\xe0\\xa5\\x8b\\xe0\\xa4\\xaa\\xe0\\xa4\\xb9\\xe0\\xa4\\xb0 \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\x88 \\xe0\\xa4\\xa5\\xe0\\xa5\\x80\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xb8\\xe0\\xa4\\xbf\\xe0\\xa4\\x97\\xe0\\xa4\\xb0\\xe0\\xa5\\x87\\xe0\\xa4\\x9f \\xe0\\xa4\\xaa\\xe0\\xa5\\x80\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa4\\xb0 \\xe0\\xa4\\x86\\xe0\\xa4\\xaa\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x86\\xe0\\xa4\\xaa\\xe0\\xa4\\xa4\\xe0\\xa5\\x8d\\xe0\\xa4\\xa4\\xe0\\xa4\\xbf \\xe0\\xa4\\xa4\\xe0\\xa5\\x8b \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b\\xe0\\xa4\\x97\\xe0\\xa5\\x80?'\n",
            " b'\\xe0\\xa4\\x87\\xe0\\xa4\\xb8 \\xe0\\xa4\\xa6\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\x88 \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xb9\\xe0\\xa4\\xb0 \\xe0\\xa4\\x9b\\xe0\\xa4\\x83 \\xe0\\xa4\\x98\\xe0\\xa4\\x82\\xe0\\xa4\\x9f\\xe0\\xa5\\x87 \\xe0\\xa4\\xb2\\xe0\\xa5\\x87\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x81\\xe0\\xa4\\x9d\\xe0\\xa5\\x87 \\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\xb8\\xe0\\xa5\\x8d\\xe0\\xa4\\xa4\\xe0\\xa4\\xb5 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x90\\xe0\\xa4\\xb8\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x81\\xe0\\xa4\\x9d\\xe0\\xa5\\x87 \\xe0\\xa4\\x9c\\xe0\\xa5\\x8b\\xe0\\xa4\\x96\\xe0\\xa4\\xbf\\xe0\\xa4\\xae \\xe0\\xa4\\xb2\\xe0\\xa5\\x87\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe \\xe0\\xa4\\xaa\\xe0\\xa4\\xb8\\xe0\\xa4\\x82\\xe0\\xa4\\xa6 \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xa4\\xe0\\xa5\\x82\\xe0\\xa4\\xab\\xe0\\xa4\\xbc\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8 \\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa5\\x82\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xb6\\xe0\\xa4\\xb9\\xe0\\xa4\\xb0 \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xa4\\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xb9 \\xe0\\xa4\\x95\\xe0\\xa4\\xb0 \\xe0\\xa4\\xa6\\xe0\\xa4\\xbf\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\x85\\xe0\\xa4\\xaa\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2 \\xe0\\xa4\\xae\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0 \\xe0\\xa4\\x95\\xe0\\xa4\\x9f\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\x85\\xe0\\xa4\\xaa\\xe0\\xa4\\xa8\\xe0\\xa5\\x80 \\xe0\\xa4\\x89\\xe0\\xa4\\xae\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0 \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xb8\\xe0\\xa5\\x8b\\xe0\\xa4\\x9a\\xe0\\xa4\\xa8\\xe0\\xa4\\xbe \\xe0\\xa4\\x9a\\xe0\\xa4\\xbe\\xe0\\xa4\\xb9\\xe0\\xa4\\xbf\\xe0\\xa4\\x8f \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\xac\\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\xa4 \\xe0\\xa4\\xaa\\xe0\\xa5\\x88\\xe0\\xa4\\xb8\\xe0\\xa5\\x87\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x80 \\xe0\\xa4\\x94\\xe0\\xa4\\xb0\\xe0\\xa4\\xa4 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae\\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\x96\\xe0\\xa5\\x81\\xe0\\xa4\\xb6 \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xb9\\xe0\\xa5\\x82\\xe0\\xa4\\x81\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa4\\xa5\\xe0\\xa4\\xae \\xe0\\xa4\\xaa\\xe0\\xa5\\x81\\xe0\\xa4\\xb0\\xe0\\xa4\\xb8\\xe0\\xa5\\x8d\\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0 \\xe0\\xa4\\x9c\\xe0\\xa5\\x80\\xe0\\xa4\\xa4 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\x9c\\xe0\\xa5\\x81\\xe0\\xa4\\xb0\\xe0\\xa5\\x8d\\xe0\\xa4\\xae \\xe0\\xa4\\xaa\\xe0\\xa4\\xb0 \\xe0\\xa4\\xac\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2\\xe0\\xa4\\x95\\xe0\\xa5\\x81\\xe0\\xa4\\xb2 \\xe0\\xa4\\xad\\xe0\\xa5\\x80 \\xe0\\xa4\\xaa\\xe0\\xa4\\x9b\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82 \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae \\xe0\\xa4\\x85\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9b\\xe0\\xa4\\xbe \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xae \\xe0\\xa4\\x95\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb0\\xe0\\xa4\\xb9\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b\\xe0\\xa5\\xa4 \\xe0\\xa4\\x90\\xe0\\xa4\\xb8\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa4\\xe0\\xa5\\x87 \\xe0\\xa4\\xb0\\xe0\\xa4\\xb9\\xe0\\xa5\\x8b\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x89\\xe0\\xa4\\xa8 \\xe0\\xa4\\xb8\\xe0\\xa4\\xad\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa4\\xbe\\xe0\\xa4\\xb8 \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\x88\\xe0\\xa4\\x95\\xe0\\xa4\\xb2 \\xe0\\xa4\\xb9\\xe0\\xa5\\x88\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe \\xe0\\xa4\\xa4\\xe0\\xa5\\x81\\xe0\\xa4\\xae \\xe0\\xa4\\xad\\xe0\\xa4\\x97\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xb5\\xe0\\xa4\\xbf\\xe0\\xa4\\xb6\\xe0\\xa5\\x8d\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\xb8 \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa4\\xe0\\xa5\\x87 \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b?'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\x90\\xe0\\xa4\\xb8\\xe0\\xa5\\x80 \\xe0\\xa4\\x9a\\xe0\\xa5\\x80\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc \\xe0\\xa4\\xa2\\xe0\\xa5\\x82\\xe0\\xa4\\x81\\xe0\\xa4\\xa2 \\xe0\\xa4\\xb0\\xe0\\xa4\\xb9\\xe0\\xa4\\xbe \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe \\xe0\\xa4\\x9c\\xe0\\xa4\\xbf\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa4\\xbe \\xe0\\xa4\\x85\\xe0\\xa4\\xb8\\xe0\\xa5\\x8d\\xe0\\xa4\\xa4\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa5\\x8d\\xe0\\xa4\\xb5 \\xe0\\xa4\\x95\\xe0\\xa4\\xad\\xe0\\xa5\\x80 \\xe0\\xa4\\xa5\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x80 \\xe0\\xa4\\xa8\\xe0\\xa4\\xb9\\xe0\\xa5\\x80\\xe0\\xa4\\x82\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\xac\\xe0\\xa5\\x87\\xe0\\xa4\\xb9\\xe0\\xa5\\x8b\\xe0\\xa4\\xb6\\xe0\\xa5\\x80 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x9a\\xe0\\xa4\\xb2\\xe0\\xa4\\xbe \\xe0\\xa4\\x97\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb6\\xe0\\xa4\\xac\\xe0\\xa5\\x8d\\xe0\\xa4\\xa6\\xe0\\xa4\\x95\\xe0\\xa5\\x8b\\xe0\\xa4\\xb6 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\x89\\xe0\\xa4\\xb8 \\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa4\\x82\\xe0\\xa4\\xb6 \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xa2\\xe0\\xa5\\x82\\xe0\\xa4\\x81\\xe0\\xa4\\xa2\\xe0\\xa5\\x8b\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\x9f\\xe0\\xa5\\x89\\xe0\\xa4\\xae \\xe0\\xa4\\x85\\xe0\\xa4\\xaa\\xe0\\xa4\\xa8\\xe0\\xa5\\x87 \\xe0\\xa4\\xaa\\xe0\\xa4\\xbf\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\x9c\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa5\\x87 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa5\\x87 \\xe0\\xa4\\xae\\xe0\\xa5\\x87\\xe0\\xa4\\x82 \\xe0\\xa4\\xac\\xe0\\xa4\\xb9\\xe0\\xa5\\x81\\xe0\\xa4\\xa4 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\xa4 \\xe0\\xa4\\x95\\xe0\\xa4\\xb0\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x88 \\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82 \\xe0\\xa4\\x85\\xe0\\xa4\\x82\\xe0\\xa4\\x97\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa5\\x87\\xe0\\xa4\\x9c\\xe0\\xa4\\xbc\\xe0\\xa5\\x80 \\xe0\\xa4\\xaa\\xe0\\xa4\\xa2\\xe0\\xa4\\xbc \\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa4\\xa4\\xe0\\xa4\\xbe \\xe0\\xa4\\xb9\\xe0\\xa5\\x82\\xe0\\xa4\\x81\\xe0\\xa5\\xa4'\n",
            " b'\\xe0\\xa4\\xb5\\xe0\\xa4\\xb9 \\xe0\\xa4\\x85\\xe0\\xa4\\xab\\xe0\\xa4\\xbc\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\xb9 \\xe0\\xa4\\xb8\\xe0\\xa4\\x9a \\xe0\\xa4\\xa8\\xe0\\xa4\\xbf\\xe0\\xa4\\x95\\xe0\\xa4\\xb2\\xe0\\xa5\\x80\\xe0\\xa5\\xa4'], shape=(32,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for i, j in train_ds.take(1):\n",
        "    print('i: ',i)\n",
        "    print('j: ', j)\n",
        "    # print('j decoded: ',j.numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3DdjsaS4aqs"
      },
      "source": [
        "# Text Vectorization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZoplDkntjFxL"
      },
      "outputs": [],
      "source": [
        "output_sequence_length = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yZj0w70q0tne"
      },
      "outputs": [],
      "source": [
        "eng_vectorizer = tf.keras.layers.TextVectorization(standardize = tf_lower_and_split_punct_en, output_sequence_length= output_sequence_length)\n",
        "hin_vectorizer = tf.keras.layers.TextVectorization(standardize = tf_lower_and_split_punct_hi, output_sequence_length= output_sequence_length+1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lj-Y5ei_0tmG",
        "outputId": "3d65ae50-d0fb-4353-d977-351ecb56e981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "# Adapting to textvectorizer\n",
        "eng_vectorizer.adapt(train_ds.map(lambda x, y: x))\n",
        "hin_vectorizer.adapt(train_ds.map(lambda x, y: y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msq7v_jN0tkT",
        "outputId": "f327f828-8895-4160-e204-499ea08e1093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maxtokens:\n",
            "English :  2359\n",
            "Hindi:  3016\n"
          ]
        }
      ],
      "source": [
        "max_token_english = len(eng_vectorizer.get_vocabulary())\n",
        "max_token_hindi = len(hin_vectorizer.get_vocabulary())\n",
        "\n",
        "print('Maxtokens:')\n",
        "print( 'English : ', max_token_english)\n",
        "print('Hindi: ', max_token_hindi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBovvXnn0tjF",
        "outputId": "c2f0c507-45dc-4979-fce5-843aa524080e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  उन्होंने मेरी का| मज़ाक उड़ाया\n",
            "\n",
            "Encoded text: ,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(201,), dtype=int64, numpy=\n",
              "array([   2,  173,   40,   20, 1446,  369,    1,    3,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "print('Text: ',some_hindi_text)\n",
        "print('\\nEncoded text: ,')\n",
        "hin_vectorizer(some_hindi_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM2zCVr60tgA"
      },
      "source": [
        "## Mapping Vectorizer to dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fTsnsCVwjFxP"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5UvErrnz0teP"
      },
      "outputs": [],
      "source": [
        "def make_vec(x, y ):\n",
        "    x, y = eng_vectorizer(x), hin_vectorizer(y)\n",
        "\n",
        "    y_in = y[:,:-1]\n",
        "    y_out = y[:,1:]\n",
        "    return (x,y_in), y_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2TtoPhnZ0tc7"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(make_vec) #.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(make_vec) # .batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6qd2-dCQjFxR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6BTOBm3i0tbL",
        "outputId": "8a3a6b3d-8e44-4da6-aa16-fff27d4827b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[   2    8   34 ...    0    0    0]\n",
            " [   2   31   29 ...    0    0    0]\n",
            " [   2   35 2309 ...    0    0    0]\n",
            " ...\n",
            " [   2  264   88 ...    0    0    0]\n",
            " [   2   31   49 ...    0    0    0]\n",
            " [   2   26    1 ...    0    0    0]], shape=(32, 200), dtype=int64)\n",
            "\n",
            "tf.Tensor(\n",
            "[[   8   34  146 ...    0    0    0]\n",
            " [  31   29  568 ...    0    0    0]\n",
            " [  35 2309   14 ...    0    0    0]\n",
            " ...\n",
            " [ 264   88  253 ...    0    0    0]\n",
            " [  31   49  168 ...    0    0    0]\n",
            " [  26    1  736 ...    0    0    0]], shape=(32, 200), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for i,j in val_ds.take(1):\n",
        "    print(i[1])\n",
        "    print()\n",
        "    print(j)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkUCiddP0tRf"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYUlG5J1jFxT"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Tt4J-fOx0tP5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, text_processor, units, embedding_dims = 32):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.units = units\n",
        "        # self.return_state = return_state\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units, mask_zero=True)\n",
        "\n",
        "        # The RNN layer processes those vectors sequentially.\n",
        "        self.rnn = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='sum',\n",
        "            layer=tf.keras.layers.LSTM(units, \n",
        "                                       return_sequences = True, \n",
        "                                       return_state = True,\n",
        "                                       recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        # 2. The embedding layer looks up the embedding vector for each token.\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # 3. The GRU processes the sequence of embeddings.\n",
        "        *x, state_h, state_c = self.rnn(x)\n",
        "        tf.print('after encoder return sequence true: ',len(x) )\n",
        "        state = [state_h, state_c]\n",
        "    \n",
        "        return x, state\n",
        "\n",
        "    def convert_input(self, texts):\n",
        "        texts = tf.convert_to_tensor(texts)\n",
        "        if len(texts.shape) == 0:\n",
        "            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "        context = self.text_processor(texts)\n",
        "        context = self(context)\n",
        "        return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_LCPt7qjFxU"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BsaIPmwK0tOQ"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, x, context):\n",
        "\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=x,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "\n",
        "        # Cache the attention scores for plotting later.\n",
        "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "        self.last_attention_weights = attn_scores\n",
        "\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PM0TckqjFxV"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9mOtgmJw0tMk"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, text_processor, units, embedding_dims = 32):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.word_to_id = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "        self.id_to_word = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n",
        "        self.start_token = self.word_to_id('[START]')\n",
        "        self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "\n",
        "        # 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units, mask_zero=True)\n",
        "\n",
        "        # 2. The RNN keeps track of what's been generated so far.\n",
        "        self.rnn = tf.keras.layers.LSTM(units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttention(units)\n",
        "\n",
        "        # 4. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Rix8TVjFxX"
      },
      "source": [
        "### Decoder call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7vLwbSZi0tK3"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "\n",
        "    # 1. Lookup the embeddings\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # 2. Process the target sequence.\n",
        "    x = self.rnn(x, initial_state=state)\n",
        "    tf.print('decoder output: ', len(x))\n",
        "    # 3. Use the RNN output as the query for the attention over the context.\n",
        "    x = self.attention(x, context)\n",
        "    self.last_attention_weights = self.attention.last_attention_weights\n",
        "\n",
        "\n",
        "    # Step 4. Generate logit predictions for the next token.\n",
        "    logits = self.output_layer(x)\n",
        "\n",
        "    if return_state:\n",
        "        return logits, state\n",
        "    else:\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6rWI_DmA0tJB"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "    batch_size = tf.shape(context)[0]\n",
        "    start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "    embedded = self.embedding(start_tokens)\n",
        "    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CmQFKqTV0tHT"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "    words = self.id_to_word(tokens)\n",
        "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VtcX4VA00tFx"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "    logits, state = self(context, next_token, state = state, return_state=True) \n",
        "\n",
        "    if temperature == 0.0:\n",
        "        next_token = tf.argmax(logits, axis=-1)\n",
        "    else:\n",
        "        logits = logits[:, -1, :]/temperature\n",
        "        next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (next_token == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "    return next_token, done, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QbTvfGlI0tCK",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# class Translator(tf.keras.Model):\n",
        "#     @classmethod\n",
        "#     def add_method(cls, fun):\n",
        "#         setattr(cls, fun.__name__, fun)\n",
        "#         return fun\n",
        "\n",
        "#     def __init__(self, units, context_text_processor, target_text_processor):\n",
        "#         super().__init__()\n",
        "#         # Build the encoder and decoder\n",
        "#         encoder = Encoder(context_text_processor, units)\n",
        "#         decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "        \n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         context, x = inputs\n",
        "#         tf.print('Before encoder-decoder')\n",
        "#         # tf.print('inputs : ',inputs.shape)\n",
        "#         tf.print('context: ',context.shape)\n",
        "#         tf.print('x      : ',x.shape)\n",
        "#         context = self.encoder(context)\n",
        "#         tf.print()\n",
        "#         logits = self.decoder(context, x)\n",
        "#         tf.print('--'*20)\n",
        "#         tf.print('After encoder-decoder')\n",
        "#         tf.print('context: ',context.shape)\n",
        "#         tf.print('logits : ',logits.shape)\n",
        "#     #TODO(b/250038731): remove this\n",
        "#         try:\n",
        "#           # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "#             del logits._keras_mask\n",
        "#         except AttributeError:\n",
        "#             pass\n",
        "\n",
        "#         return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "w0JH_eH3jFxc"
      },
      "outputs": [],
      "source": [
        "class Translator2(tf.keras.Model):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, units, context_text_processor, target_text_processor):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.context_text_processor = context_text_processor\n",
        "        self.target_text_processor = target_text_processor\n",
        "\n",
        "        self.context_vocab_size = context_text_processor.vocabulary_size()\n",
        "        self.target_vocab_size = target_text_processor.vocabulary_size()\n",
        "        \n",
        "        self.word_to_id = tf.keras.layers.StringLookup(vocabulary=target_text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "        self.id_to_word = tf.keras.layers.StringLookup(vocabulary=target_text_processor.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n",
        "    \n",
        "        self.units = units\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding1 = tf.keras.layers.Embedding(self.context_vocab_size, units, mask_zero=True)\n",
        "        self.embedding2 = tf.keras.layers.Embedding(self.target_vocab_size, units, mask_zero=True)\n",
        "\n",
        "        # The RNN layer processes those vectors sequentially.\n",
        "        self.encoder = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='concat',\n",
        "            layer=tf.keras.layers.GRU(units, \n",
        "                                       return_sequences = True, \n",
        "                                       return_state = True,\n",
        "                                       recurrent_initializer='glorot_uniform'))\n",
        "        \n",
        "        self.decoder = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='concat',\n",
        "            layer=tf.keras.layers.GRU(units, \n",
        "                                       return_sequences = True, \n",
        "                                       return_state = True,\n",
        "                                       recurrent_initializer='glorot_uniform'))\n",
        "        \n",
        "        \n",
        "        self.start_token = self.word_to_id('[START]')\n",
        "        self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "        # 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttention(units)\n",
        "        self.last_attention_weights = None\n",
        "        # 4. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.output_layer = tf.keras.layers.Dense(self.target_vocab_size)\n",
        "        \n",
        "        self.encoder_state = None\n",
        "    def call(self, X, y=None):\n",
        "        context, que = X\n",
        "        \n",
        "        #Encoding\n",
        "        # 1. embedding\n",
        "        x = self.embedding1(context)\n",
        "        # tf.print('after embedding: x shape: ',x.shape )\n",
        "        encoder_context, enc_h, enc_c = self.encoder(x)\n",
        "        self.encoder_state = [enc_h, enc_c]\n",
        "        # tf.print('after encodeing: x shape: ',len(x) )\n",
        "\n",
        "        # encoder_context, encoder_state = x\n",
        "        #Decoding\n",
        "        x = self.embedding2(que)\n",
        "        decoder_context, decoder_state_h, decoder_state_c = self.decoder(x, initial_state=self.encoder_state)\n",
        "        \n",
        "        x = self.attention(decoder_context, encoder_context)\n",
        "        self.last_attention_weights = self.attention.last_attention_weights\n",
        "        # tf.print('decoder context shape: ', len(decoder_context))\n",
        "        # logits\n",
        "        logits = self.output_layer(x)\n",
        "            # tf.print('\\n')\n",
        "        #TODO(b/250038731): remove this\n",
        "        try:\n",
        "          # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def convert_input(self, texts):\n",
        "\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "        texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.context_text_processor(texts)\n",
        "    context = self(context)\n",
        "    return context"
      ],
      "metadata": {
        "id": "IXzwfGpMpU3G"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  context = self.decoder.get_initial_state(embedded)[0]\n",
        "  return start_tokens, done, context "
      ],
      "metadata": {
        "id": "E-FOjbqi6aDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator2.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "    context = self.convert_input(texts)\n",
        "    batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "    tokens = []\n",
        "    attention_weights = []\n",
        "    next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Generate the next token\n",
        "        next_token, done, state = self.decoder.get_next_token(context, next_token, done,  state, temperature)\n",
        "\n",
        "        # Collect the generated tokens\n",
        "        tokens.append(next_token)\n",
        "        attention_weights.append(self.decoder.last_attention_weights)\n",
        "\n",
        "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "            break\n",
        "\n",
        "    # Stack the lists of tokens and attention weights.\n",
        "    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "    self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "    result = self.decoder.tokens_to_text(tokens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "Di7FvIMLpEVZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = model.translate(['She loves me'])\n",
        "ss"
      ],
      "metadata": {
        "id": "fNCLmMr_sfW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "lhj-jdpS0tAI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = Translator2(UNITS, eng_vectorizer, hin_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dSxxNTtT0s2z",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# sample = train_df.sample(5)\n",
        "# some_hindi_text = sample['hindi'].to_numpy()\n",
        "# some_eng_text = sample['english'].to_numpy()\n",
        "\n",
        "# print(some_hindi_text)\n",
        "# print(some_eng_text)\n",
        "\n",
        "# vectorized_eng_text = eng_vectorizer(some_eng_text)\n",
        "# vectorized_eng_text[:,:10]\n",
        "\n",
        "# vectorized_hindi_text = hin_vectorizer(some_hindi_text)\n",
        "# vectorized_hindi_text[:,:10]\n",
        "\n",
        "# vec_hindi_in = vectorized_hindi_text[:,:-1]\n",
        "# vec_hindi_out = vectorized_hindi_text[:,1:]\n",
        "# print(vec_hindi_in[:,:10])\n",
        "# print()\n",
        "# print(vec_hindi_out[:,:10])\n",
        "\n",
        "# encoder = Encoder(eng_vectorizer, UNITS)\n",
        "# # context_eng = encoder((vectorized_eng_text))\n",
        "\n",
        "# new_tx = encoder.convert_input(['hey man'])\n",
        "\n",
        "# # context_eng\n",
        "\n",
        "# # decoder = Decoder(hin_vectorizer, UNITS)\n",
        "# # logits = decoder(context_eng, vec_hindi_in)\n",
        "# # logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5DMM5XHX0syX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wrQnQhGM0stC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IGw3VSmG0sqa"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "YacbS2vjjFxg"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-i_XW14UjFxg"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "nQ5eDngHjFxh"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30\n",
        "CKPT_DIR = './model_checkpoint'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "mw84m4ZTjFxh"
      },
      "outputs": [],
      "source": [
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(CKPT_DIR,  f\"{datetime.now().strftime('%m:%d:%Y, %H:%M:%S')}\"),\n",
        "    monitor= 'loss',\n",
        "    verbose= 0,\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True,\n",
        "    mode= 'auto',\n",
        "    save_freq='epoch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tqtKPvmAjFxi"
      },
      "outputs": [],
      "source": [
        "data_amount = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "rg1ZWQV90sn9",
        "outputId": "8953f6c9-b906-45da-9df0-322cefa4f312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "60/60 [==============================] - 36s 281ms/step - loss: 6.7181 - masked_acc: 0.1181 - masked_loss: 6.7181 - val_loss: 6.1948 - val_masked_acc: 0.1210 - val_masked_loss: 6.1868\n",
            "Epoch 2/30\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 5.6870 - masked_acc: 0.1509 - masked_loss: 5.6865 - val_loss: 5.5420 - val_masked_acc: 0.1672 - val_masked_loss: 5.5457\n",
            "Epoch 3/30\n",
            "60/60 [==============================] - 5s 76ms/step - loss: 4.9746 - masked_acc: 0.2447 - masked_loss: 4.9746 - val_loss: 4.8483 - val_masked_acc: 0.3114 - val_masked_loss: 4.8428\n",
            "Epoch 4/30\n",
            "60/60 [==============================] - 3s 55ms/step - loss: 4.1933 - masked_acc: 0.3626 - masked_loss: 4.1933 - val_loss: 4.2427 - val_masked_acc: 0.3878 - val_masked_loss: 4.2411\n",
            "Epoch 5/30\n",
            "60/60 [==============================] - 3s 57ms/step - loss: 3.5661 - masked_acc: 0.4353 - masked_loss: 3.5465 - val_loss: 3.7464 - val_masked_acc: 0.4401 - val_masked_loss: 3.7496\n",
            "Epoch 6/30\n",
            "60/60 [==============================] - 4s 67ms/step - loss: 3.0769 - masked_acc: 0.5032 - masked_loss: 3.0631 - val_loss: 3.3147 - val_masked_acc: 0.4910 - val_masked_loss: 3.3236\n",
            "Epoch 7/30\n",
            "60/60 [==============================] - 3s 50ms/step - loss: 2.5645 - masked_acc: 0.5794 - masked_loss: 2.5645 - val_loss: 2.9669 - val_masked_acc: 0.5847 - val_masked_loss: 2.9543\n",
            "Epoch 8/30\n",
            "60/60 [==============================] - 3s 51ms/step - loss: 2.1663 - masked_acc: 0.6482 - masked_loss: 2.1660 - val_loss: 2.7023 - val_masked_acc: 0.6183 - val_masked_loss: 2.6986\n",
            "Epoch 9/30\n",
            "60/60 [==============================] - 3s 55ms/step - loss: 1.8625 - masked_acc: 0.7028 - masked_loss: 1.8518 - val_loss: 2.4607 - val_masked_acc: 0.6870 - val_masked_loss: 2.4526\n",
            "Epoch 10/30\n",
            "60/60 [==============================] - 4s 61ms/step - loss: 1.5020 - masked_acc: 0.7656 - masked_loss: 1.5020 - val_loss: 2.2245 - val_masked_acc: 0.7127 - val_masked_loss: 2.2169\n",
            "Epoch 11/30\n",
            "60/60 [==============================] - 3s 50ms/step - loss: 1.2987 - masked_acc: 0.8102 - masked_loss: 1.2842 - val_loss: 2.0586 - val_masked_acc: 0.7443 - val_masked_loss: 2.0708\n",
            "Epoch 12/30\n",
            "60/60 [==============================] - 3s 47ms/step - loss: 1.0896 - masked_acc: 0.8369 - masked_loss: 1.1065 - val_loss: 1.9438 - val_masked_acc: 0.7635 - val_masked_loss: 1.9521\n",
            "Epoch 13/30\n",
            "60/60 [==============================] - 3s 50ms/step - loss: 0.8594 - masked_acc: 0.8979 - masked_loss: 0.8594 - val_loss: 1.8615 - val_masked_acc: 0.7951 - val_masked_loss: 1.8582\n",
            "Epoch 14/30\n",
            "60/60 [==============================] - 4s 61ms/step - loss: 0.7356 - masked_acc: 0.9217 - masked_loss: 0.7268 - val_loss: 1.7609 - val_masked_acc: 0.7943 - val_masked_loss: 1.7690\n",
            "Epoch 15/30\n",
            "60/60 [==============================] - 3s 51ms/step - loss: 0.6158 - masked_acc: 0.9395 - masked_loss: 0.6409 - val_loss: 1.7834 - val_masked_acc: 0.8066 - val_masked_loss: 1.7805\n",
            "Epoch 16/30\n",
            "60/60 [==============================] - 3s 48ms/step - loss: 0.4630 - masked_acc: 0.9735 - masked_loss: 0.4630 - val_loss: 1.6580 - val_masked_acc: 0.8124 - val_masked_loss: 1.6718\n",
            "Epoch 17/30\n",
            "60/60 [==============================] - 3s 56ms/step - loss: 0.3880 - masked_acc: 0.9840 - masked_loss: 0.3843 - val_loss: 1.6275 - val_masked_acc: 0.8279 - val_masked_loss: 1.6301\n",
            "Epoch 18/30\n",
            "60/60 [==============================] - 3s 55ms/step - loss: 0.3137 - masked_acc: 0.9926 - masked_loss: 0.3116 - val_loss: 1.4902 - val_masked_acc: 0.8435 - val_masked_loss: 1.4958\n",
            "Epoch 19/30\n",
            "60/60 [==============================] - 3s 49ms/step - loss: 0.2197 - masked_acc: 0.9985 - masked_loss: 0.2197 - val_loss: 1.5318 - val_masked_acc: 0.8443 - val_masked_loss: 1.5442\n",
            "Epoch 20/30\n",
            "60/60 [==============================] - 3s 51ms/step - loss: 0.1802 - masked_acc: 0.9990 - masked_loss: 0.1817 - val_loss: 1.4369 - val_masked_acc: 0.8630 - val_masked_loss: 1.4404\n",
            "Epoch 21/30\n",
            "60/60 [==============================] - 3s 56ms/step - loss: 0.1448 - masked_acc: 0.9997 - masked_loss: 0.1435 - val_loss: 1.5187 - val_masked_acc: 0.8533 - val_masked_loss: 1.5167\n",
            "Epoch 22/30\n",
            "60/60 [==============================] - 3s 53ms/step - loss: 0.1011 - masked_acc: 0.9999 - masked_loss: 0.1011 - val_loss: 1.5173 - val_masked_acc: 0.8596 - val_masked_loss: 1.5208\n",
            "Epoch 23/30\n",
            "60/60 [==============================] - 3s 51ms/step - loss: 0.0865 - masked_acc: 0.9998 - masked_loss: 0.0858 - val_loss: 1.4359 - val_masked_acc: 0.8598 - val_masked_loss: 1.4469\n",
            "Epoch 24/30\n",
            "60/60 [==============================] - 3s 49ms/step - loss: 0.0727 - masked_acc: 1.0000 - masked_loss: 0.0724 - val_loss: 1.4697 - val_masked_acc: 0.8622 - val_masked_loss: 1.4741\n",
            "Epoch 25/30\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.0548 - masked_acc: 0.9999 - masked_loss: 0.0548 - val_loss: 1.5210 - val_masked_acc: 0.8548 - val_masked_loss: 1.5312\n",
            "Epoch 26/30\n",
            "60/60 [==============================] - 3s 51ms/step - loss: 0.0486 - masked_acc: 1.0000 - masked_loss: 0.0482 - val_loss: 1.4926 - val_masked_acc: 0.8549 - val_masked_loss: 1.4948\n",
            "Epoch 27/30\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.0430 - masked_acc: 0.9999 - masked_loss: 0.0425 - val_loss: 1.5577 - val_masked_acc: 0.8494 - val_masked_loss: 1.5657\n",
            "Epoch 28/30\n",
            "60/60 [==============================] - 3s 47ms/step - loss: 0.0349 - masked_acc: 1.0000 - masked_loss: 0.0349 - val_loss: 1.4939 - val_masked_acc: 0.8575 - val_masked_loss: 1.4731\n",
            "Epoch 29/30\n",
            "60/60 [==============================] - 3s 58ms/step - loss: 0.0319 - masked_acc: 1.0000 - masked_loss: 0.0316 - val_loss: 1.4781 - val_masked_acc: 0.8637 - val_masked_loss: 1.4834\n",
            "Epoch 30/30\n",
            "60/60 [==============================] - 3s 51ms/step - loss: 0.0291 - masked_acc: 1.0000 - masked_loss: 0.0292 - val_loss: 1.5447 - val_masked_acc: 0.8581 - val_masked_loss: 1.5337\n"
          ]
        }
      ],
      "source": [
        "# tf.executing_eagerly(False)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch = int(data_amount*(len(train_ds)/EPOCHS)),\n",
        "\n",
        "    validation_data=val_ds.repeat(),\n",
        "    validation_steps = 5,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor = 'masked_loss', patience=3),\n",
        "    model_ckpt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "0oAu_jN60slV",
        "outputId": "4a879281-c892-48bd-867e-c38f513a4267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0e510fe430>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "# plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "XUF3LXpN0sjC",
        "outputId": "baa15237-45b2-4951-bc27-577b4a1a1a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0e51067790>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "# plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "nbmAh9W70sgO",
        "outputId": "93568ed2-9682-4f82-8ea8-50a869c42297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-5a5cae355c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mTranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m def translate(self,\n\u001b[1;32m      3\u001b[0m               \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               temperature=0.0):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Translator' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDETfmnw0sdp"
      },
      "outputs": [],
      "source": [
        "result = model.translate(['She loves me']) \n",
        "result[0].numpy().decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty6op_uUjFxl"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.title('accuracy vs epochs')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfnUjWD_jFxl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}